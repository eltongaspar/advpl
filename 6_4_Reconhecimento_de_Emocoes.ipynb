{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0BAtYEW5zYlJut8tXSToP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eltongaspar/advpl/blob/Advpl/6_4_Reconhecimento_de_Emocoes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "DOfilEfVvpCH",
        "outputId": "f77669ab-48eb-45a3-f405-87b9e47e0fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Estudo de caso\n",
        "#Reconhecimento de Emoções\n",
        "\n",
        "#Importando as bibliotecas\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import zipfile\n",
        "\n",
        "cv2.__version__\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__\n",
        "\n",
        "#Conectando com o Drive e acessando os arquivos\n",
        "# Conectando o Colab ao Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Realize o dowload da pasta Material_complementar_reconhecimento_emocoes.zip do Google Sala de Aula e transfira-a para o seu Google Drive\n",
        "# Localize o caminho da pasta no menu Arquivos, no menu lateral esquerdo\n",
        "path = \"/content/gdrive/MyDrive/Classroom/Inteligência Artificial aplicada à Visão Computacional Turma 99 - 6: 01 02 a 31 05 2024/6-4/Material_complementar_reconhecimento_emocoes.zip\"\n",
        "#print(path)\n",
        "#import os\n",
        "#file_exists = os.path.isfile(path)\n",
        "#print(file_exists)\n",
        "#zip_object = zipfile.ZipFile(file=path, mode=\"r\")\n",
        "#zip_object.extractall(\"./\")\n",
        "\n",
        "# Indique o caminho da pasta \"fer2013.zip\" para descompactá-la. São arquivos organizados conforme cada uma das classes de emoções.\n",
        "base_imgs = '/content/gdrive/MyDrive/Classroom/Inteligência Artificial aplicada à Visão Computacional Turma 99 - 6: 01 02 a 31 05 2024/6-4/Material_complementar_reconhecimento_emocoes/fer2013.zip'\n",
        "zip_object = zipfile.ZipFile(file = base_imgs, mode = 'r')\n",
        "zip_object.extractall('./')\n",
        "#zip_object.close\n",
        "\n",
        "#Acessando a base com fotos de expressões faciais\n",
        "# Arquivo que contem as informações do banco de imagens das fotos de cada classe de emoção.\n",
        "data = pd.read_csv('fer2013/fer2013.csv')\n",
        "data.tail()\n",
        "\n",
        "# Visualizando a quantidade de fotos existente em cada uma das classes de emoções.\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.hist(data['emotion'], bins = 30)\n",
        "plt.title('Imagens x emoções')\n",
        "\n",
        "# Classes: ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "#Pré-processamento\n",
        "\n",
        "# Listando os valores de pixels das imagens\n",
        "pixels = data['pixels'].tolist()\n",
        "\n",
        "# Redimensionando as imagens encontradas\n",
        "largura, altura = 48, 48\n",
        "faces = []\n",
        "amostras = 0\n",
        "for pixel_sequence in pixels:\n",
        "  face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "  face = np.asarray(face).reshape(largura, altura)\n",
        "  faces.append(face)\n",
        "\n",
        "  if (amostras < 10): # demonstrando um conjunto de 10 amostras\n",
        "    cv2_imshow(face)\n",
        "  amostras += 1\n",
        "\n",
        "  # Demonstrando a quantidade total de imagens em que foram encontradas faces.\n",
        "print('Número total de imagens no dataset: ', str(len(faces)))\n",
        "\n",
        "# Convertendo as faces das imagens em arrays\n",
        "faces = np.asarray(faces)\n",
        "\n",
        "# Demonstrando as formas das faces das imagens (quantidade, pixels x, pixels y)\n",
        "faces.shape\n",
        "\n",
        "# Expandindo as dimensões das faces das imagens (quantidade, pixels x, pixels y, quantidade de canais)\n",
        "faces = np.expand_dims(faces, -1)\n",
        "faces.shape\n",
        "\n",
        "# Definindo a função para normalizar as imagens\n",
        "def normalizar(x):\n",
        "  x = x.astype('float32')\n",
        "  x = x / 255.0\n",
        "  return x\n",
        "\n",
        "  # Normalizando as imagens das faces\n",
        "faces = normalizar(faces)\n",
        "\n",
        "# Atribuindo valores a cada uma das classes de emoções\n",
        "emocoes = pd.get_dummies(data['emotion']).values\n",
        "\n",
        "#Imports do Tensorflow/Keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "\n",
        "#Dividir em conjuntos para treinamento e validação\n",
        "# Criando os conjuntos de treinamento e validação\n",
        "X_train, X_test, y_train, y_test = train_test_split(faces, emocoes, test_size = 0.1, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 41)\n",
        "\n",
        "# Quantidade das imagens dos conjuntos\n",
        "print('Número de imagens no conjunto de treinamento:', len(X_train))\n",
        "print('Número de imagens no conjunto de teste:', len(X_test))\n",
        "print('Número de imagens no conjunto de validação:', len(X_val))\n",
        "\n",
        "# Base de dados para a matriz de confusão\n",
        "np.save('mod_xtest', X_test)\n",
        "np.save('mod_ytest', y_test)\n",
        "\n",
        "#Arquitetura do modelo da rede neural convolucional (CNN)\n",
        "#Arquitetura do modelo\n",
        "# Criando o modelo sequencial da rede neural, trazendo cada uma das camadas.\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "width, height = 48, 48\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu',\n",
        "                 input_shape=(width, height, 1), data_format = 'channels_last',\n",
        "                 kernel_regularizer = l2(0.01)))\n",
        "model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(2*2*2*num_features, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(2*2*num_features, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(2*num_features, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_labels, activation = 'softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#Compilando o modelo\n",
        "model.compile(loss = 'categorical_crossentropy', # Classificação - cálculo dos erros\n",
        "              optimizer = Adam(lr = 0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), # Atualização dos pesos / taxa decaimento e taxa aprendizagem\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "arquivo_modelo = 'modelo_01_expressoes.h5' # Traz os modelos salvos - com o conjunto dos pesos de aprendizado da rede neural\n",
        "arquivo_modelo_json = 'modelo_01_expressoes.json' # Traz a estrutura da rede neural\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor = 0.9, patience=3, verbose = 1)\n",
        "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience = 8, verbose = 1, mode = 'auto')\n",
        "checkpointer = ModelCheckpoint(arquivo_modelo, monitor='val_loss', verbose = 1, save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "#Salvando a arquitetura do modelo em um arquivo JSON\n",
        "model_json = model.to_json()\n",
        "with open(arquivo_modelo_json, 'w') as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "#Treinando o modelo\n",
        "history = model.fit(np.array(X_train), np.array(y_train),\n",
        "                    batch_size = batch_size, #64\n",
        "                    epochs = epochs, #100\n",
        "                    verbose = 1,\n",
        "                    validation_data = (np.array(X_val), np.array(y_val)),\n",
        "                    shuffle=True,\n",
        "                    callbacks=[lr_reducer, early_stopper, checkpointer])\n",
        "\n",
        "#Gerando gráfico da melhora em cada etapa do treinamento\n",
        "def plota_historico_modelo(historico_modelo):\n",
        "  fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
        "  axs[0].plot(range(1, len(historico_modelo.history['accuracy']) + 1), historico_modelo.history['accuracy'], 'r')\n",
        "  axs[0].plot(range(1, len(historico_modelo.history['val_accuracy']) + 1), historico_modelo.history['val_accuracy'], 'b')\n",
        "  axs[0].set_title('Acurácia do modelo')\n",
        "  axs[0].set_ylabel('Acurácia')\n",
        "  axs[0].set_xlabel('Epoch')\n",
        "  axs[0].legend(['training accuracy', 'validation accuracy'], loc = 'best')\n",
        "  axs[1].plot(range(1, len(historico_modelo.history['loss']) + 1), historico_modelo.history['loss'], 'r')\n",
        "  axs[1].plot(range(1, len(historico_modelo.history['val_loss']) + 1), historico_modelo.history['val_loss'], 'b')\n",
        "  axs[1].set_title('Loss do modelo')\n",
        "  axs[1].set_ylabel('Loss')\n",
        "  axs[1].set_xlabel('Epoch')\n",
        "  axs[1].legend(['training loss', 'validation loss'], loc = 'best')\n",
        "  fig.savefig('historico_modelo_mod01.png')\n",
        "\n",
        "plota_historico_modelo(history)\n",
        "\n",
        "#Verificando a acurácia do modelo\n",
        "# Relação do erro x acurárcia\n",
        "scores = model.evaluate(np.array(X_test), np.array(y_test), batch_size = batch_size) #\n",
        "scores\n",
        "\n",
        "print('Acurácia: ' + str(scores[1]))\n",
        "print('Erro: ' + str(scores[0]))\n",
        "\n",
        "\n",
        "#Carregamento dos dados para gerar a matriz de confusão\n",
        "# Valores reais e das predições\n",
        "true_y = []\n",
        "pred_y = []\n",
        "x = np.load('mod_xtest.npy')\n",
        "y = np.load('mod_ytest.npy')\n",
        "\n",
        "# Carregar o modelo salvo com a estrutura da rede neural\n",
        "json_file = open(arquivo_modelo_json, 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "# Predição dos pixels de cada uma das imagens para cada uma das emoções\n",
        "y_pred = loaded_model.predict(x)\n",
        "\n",
        "# Transformar as predições em uma lista\n",
        "yp = y_pred.tolist()\n",
        "yt = y.tolist() # com as respostas reais\n",
        "count = 0\n",
        "\n",
        "# Quantidade de registros na base de dados de teste\n",
        "len(y)\n",
        "\n",
        "# Obtendo o maior valor da probabilidade\n",
        "for i in range(len(y)):\n",
        "  yy = max(yp[i])\n",
        "  yyt = max(yt[i])\n",
        "  pred_y.append(yp[i].index(yy))\n",
        "  true_y.append(yt[i].index(yyt))\n",
        "  if (yp[i].index(yy) == yt[i].index(yyt)):\n",
        "    count += 1\n",
        "\n",
        "acc = (count / len(y)) * 100\n",
        "\n",
        "# Demonstrar o valor da acurácia\n",
        "print('Acurácia no conjunto de teste: ' + str(acc))\n",
        "\n",
        "\n",
        "# Salvar os valores das emoções e predições\n",
        "np.save('truey_mod01', true_y)\n",
        "np.save('predy_mod01', pred_y)\n",
        "\n",
        "#Gerando a Matriz de Confusão\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_true = np.load('truey_mod01.npy')\n",
        "y_pred = np.load('predy_mod01.npy')\n",
        "\n",
        "# Matriz de acertos classe por classe\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "expressoes = ['Raiva', 'Nojo', 'Medo', 'Feliz', 'Triste', 'Surpreso', 'Neutro']\n",
        "titulo = 'Matriz de Confusão'\n",
        "print(cm)\n",
        "\n",
        "# Construindo a matriz de confusão\n",
        "import itertools\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title(titulo)\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(expressoes))\n",
        "plt.xticks(tick_marks, expressoes, rotation = 45)\n",
        "plt.yticks(tick_marks, expressoes)\n",
        "fmt = 'd'\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "  plt.text(j, i, format(cm[i, j], fmt), horizontalalignment='center', color='white' if cm[i,j] > thresh else 'black')\n",
        "\n",
        "plt.ylabel('Classificação correta')\n",
        "plt.xlabel('Predição')\n",
        "plt.savefig('matriz_confusao_mod01.png')\n",
        "\n",
        "# Localize o arquivo \"salagooglemeet.jpg\" para realizar o reconhecimento das emoções\n",
        "imagem = cv2.imread('/content/testes/salagooglemeet.jpg')\n",
        "cv2_imshow(imagem)\n",
        "\n",
        "# Transformando a imagem original em escala de cinza\n",
        "original = imagem.copy()\n",
        "gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)\n",
        "\n",
        "# Utilize o arquivo haarcascade de reconhecimento facial para detectar as faces na imagem\n",
        "face_cascade = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')\n",
        "faces = face_cascade.detectMultiScale(gray, 1.1, 3)\n",
        "\n",
        "# Reconhecendo as emoções nas faces detectadas, criando um retângulo e indicação textual na imagem original.\n",
        "for (x, y, w, h) in faces:\n",
        "  cv2.rectangle(original, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
        "  roi_gray = gray[y:y + h, x:x + w]\n",
        "  roi_gray = roi_gray.astype('float') / 255.0\n",
        "  cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
        "  prediction = loaded_model.predict(cropped_img)[0]\n",
        "  cv2.putText(original, expressoes[int(np.argmax(prediction))], (x, y - 10),\n",
        "              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "cv2_imshow(original)\n",
        "\n"
      ]
    }
  ]
}